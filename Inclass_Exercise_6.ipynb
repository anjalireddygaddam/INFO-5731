{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inclass Exercise_6",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAJZ14eOs8tnhuBrZGqH03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalireddygaddam/INFO-5731/blob/main/Inclass_Exercise_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ2WXztu1DXI"
      },
      "source": [
        "The sixth in-class-exercise (20 points in total, 3/2/2021)\r\n",
        "1. Rule-based information extraction (10 points)\r\n",
        "\r\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the titles of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nHpP6W80v9Z"
      },
      "source": [
        "import pandas as pd\r\n",
        "google_scholar_titles = pd.read_csv('titles.csv', encoding = \"ISO-8859-1\")\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d15Z2rTM01jd",
        "outputId": "a50478a5-0746-4be9-9ece-ae740b36c26e"
      },
      "source": [
        "t = lambda x: x['Author'].split(\",\")\r\n",
        "authors = google_scholar_titles.apply(t, axis=1).tolist()\r\n",
        "\r\n",
        "dictionary = {}\r\n",
        "\r\n",
        "print(\"Repeated Authors:\")\r\n",
        "for i in range(len(authors)):\r\n",
        "  if dictionary.get((authors[i][0])) == None:\r\n",
        "    dictionary[(authors[i][0])] = \"\"\r\n",
        "  else:\r\n",
        "    print((authors[i][0]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Repeated Authors:\n",
            "F Provost\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "W Van Der Aalst - Process mining\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n",
            "W Van Der Aalst - Process mining\n",
            "V Dhar - Communications of the ACM\n",
            "F Provost\n",
            "F Provost\n",
            "R Vershynin - 2018 - books.google.com\n",
            "G Peyré\n",
            "MA Waller\n",
            "E Bolyen\n",
            "M Swan - Big data\n",
            "K Kirkpatrick - Communications of the ACM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhl2qeDu06pL",
        "outputId": "ad45ac7b-6a26-42e4-a268-c4987a836002"
      },
      "source": [
        "import spacy\r\n",
        "from spacy.matcher import Matcher\r\n",
        "\r\n",
        "nlp = spacy.load(\"en_core_web_sm\")\r\n",
        "match = Matcher(nlp.vocab)\r\n",
        "patterna= [{\"LOWER\": \"techniques\"}]\r\n",
        "patternb= [{\"TEXT\": {\"REGEX\": \"^(N|n)\\w+$\"}},{\"TEXT\": {\"REGEX\": \"^(L|l)\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^(P|p)\\w+$\"}},\r\n",
        "           {\"TEXT\": {\"REGEX\": \"^(I|i)(N|n)$\"}},{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\r\n",
        "patternc = [{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^[Uu](\\.?|sing)$\"}}, {\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\r\n",
        "patternd= [{\"TEXT\": {\"REGEX\": \"^\\w+$\"}}, {\"TEXT\": {\"REGEX\": \"^[Bb](\\.?|ased)$\"}}, {\"TEXT\": {\"REGEX\": \"^\\w+$\"}}]\r\n",
        "match.add(\"Techniques\", None, patterna)\r\n",
        "match.add(\"Uses\", None, patternb)\r\n",
        "match.add(\"methods\", None, patternc)\r\n",
        "match.add(\"based\", None, patternd)\r\n",
        "\r\n",
        "for title in google_scholar_titles['Article Title']:\r\n",
        "  text_doc = nlp(title)\r\n",
        "  matches = match(text_doc)\r\n",
        "  for match_id, start, end in matches:\r\n",
        "      span = text_doc[start:end]\r\n",
        "      print(title)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n",
            "Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPT5fK041BL5",
        "outputId": "f342ff31-198c-4b99-b47c-c4728d93e4b3"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('all')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEvcRFHS1UV6"
      },
      "source": [
        "2. Domain-specific information extraction (10 points)\r\n",
        "For the legal case used in the data cleaning exercise: 01-05-1 Adams v Tanner.txt, use legalNLP to extract the following inforation from the text (if the information is not exist, just print None):\r\n",
        "\r\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\r\n",
        "\r\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\r\n",
        "\r\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\r\n",
        "\r\n",
        "(4) companies, e.g., “Lexpredict LLC”\r\n",
        "\r\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\r\n",
        "\r\n",
        "(6) constraints, e.g., “no more than”\r\n",
        "\r\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\r\n",
        "\r\n",
        "(8) courts, e.g., “Supreme Court of New York”\r\n",
        "\r\n",
        "(9) CUSIP, e.g., “392690QT3”\r\n",
        "\r\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\r\n",
        "\r\n",
        "(11) definitions, e.g., “Term shall mean …”\r\n",
        "\r\n",
        "(12) distances, e.g., “fifteen miles”\r\n",
        "\r\n",
        "(13) durations, e.g., “ten years” or “thirty days”\r\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\r\n",
        "\r\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\r\n",
        "\r\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\r\n",
        "\r\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\r\n",
        "\r\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\r\n",
        "\r\n",
        "(19) regulations, e.g., “32 CFR 170”\r\n",
        "\r\n",
        "(20) trademarks, e.g., “MyApp (TM)”\r\n",
        "\r\n",
        "(21) URLs, e.g., “http://acme.com/”\r\n",
        "\r\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\r\n",
        "\r\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "id4ymJEl1Tbu",
        "outputId": "8a4d8d7d-383e-42f6-c9c1-164639939f32"
      },
      "source": [
        "!pip install LexNLP\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting LexNLP\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/8f/775b5718bdee8b11bb06a4a49172abec78f9e94b865a7382b3b7d5f69cc5/lexnlp-1.8.0-py3-none-any.whl (9.8MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8MB 3.6MB/s \n",
            "\u001b[?25hCollecting pycountry==20.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 44.2MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/8f/29d5688614f9bba59931683d5d353d738d4a3007833219ee19c455732753/numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 319kB/s \n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 44.2MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/45/ff9df4beceab76f979ee0ea7f5d248596aa5b0c179aa3d30589a3f4549eb/scipy-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 1.3MB/s \n",
            "\u001b[?25hCollecting num2words==0.5.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[?25hCollecting datefinder-lexpredict==0.6.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/45/d1/e80c60a7c23a4b16338f33345be45c64bd6ff4ef5ab67350b8c94325b8b6/datefinder_lexpredict-0.6.2.1-py2.py3-none-any.whl\n",
            "Collecting scikit-learn==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/7e/74e707b66490d4eb05f702966ad0990881127acecf9d5cdcef3c95ec6c16/scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 42.7MB/s \n",
            "\u001b[?25hCollecting reporters-db==2.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/e9/498bada93e69e3162a027d9285e852c464d66aae23ec3c845700ee117414/reporters_db-2.0.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.9MB/s \n",
            "\u001b[?25hCollecting dateparser==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/9d/51126ac615bbc4418478d725a5fa1a0f112059f6f111e4b48cfbe17ef9d0/dateparser-0.7.2-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 33.9MB/s \n",
            "\u001b[?25hCollecting joblib==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 51.0MB/s \n",
            "\u001b[?25hCollecting regex==2020.7.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/10/a5f40a296a199dda90432ba0af4dc4221aa5cde31c62b6088c88df971e9e/regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 36.8MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/e6/2d47835f91eb010036be207581fa113fb4e3822ec1b4bafb0d3d105fede6/pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 40.4MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.3MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/afe2315e08a38967f8a3036bbe7e38b428e9b7a90e823a83d0d49df1adf5/gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 107kB/s \n",
            "\u001b[?25hCollecting us==2.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/88/04/04323aefa1871de30286d3decae7706481c73bd428cf0c08e158bfa259a6/us-2.0.2.tar.gz\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->LexNLP) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->LexNLP) (4.41.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->LexNLP) (0.6.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->LexNLP) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->LexNLP) (2.8.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==2.0.3->LexNLP) (1.15.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->LexNLP) (1.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->LexNLP) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->LexNLP) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->LexNLP) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->LexNLP) (2.10)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->LexNLP) (4.2.0)\n",
            "Collecting jellyfish==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/3f/60ac86fb43dfbf976768e80674b5538e535f6eca5aa7806cf2fdfd63550f/jellyfish-0.6.1.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycountry, nltk, us, jellyfish\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=0a7b0d9c742965f72985cc96f3264458d8282f1c43dc6e835dc87c89abaf2ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434675 sha256=515c421625d58492eec459fa854148a956419d3679469ae812d858051c8a9457\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-2.0.2-cp37-none-any.whl size=11929 sha256=dfb79a5233b6e43d552459a64127ebdfd5f4a563235dee1eb95fb3e6455ac046\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/16/45/6453383ffa495670f0f6b80a3e697a9771d98cfbaf8b451e73\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.6.1-cp37-cp37m-linux_x86_64.whl size=72113 sha256=e8eb1c238923be9dc61fa1e2048b403ac613d455b73e37c5073d1c22aeeed429\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/6f/33/92bb9a4b4562a60ba6a80cedbab8907e48bc7a8b1f369ea0ae\n",
            "Successfully built pycountry nltk us jellyfish\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pycountry, numpy, joblib, regex, nltk, scipy, num2words, datefinder-lexpredict, threadpoolctl, scikit-learn, reporters-db, dateparser, pandas, Unidecode, requests, gensim, jellyfish, us, LexNLP\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed LexNLP-1.8.0 Unidecode-1.1.1 datefinder-lexpredict-0.6.2.1 dateparser-0.7.2 gensim-3.8.3 jellyfish-0.6.1 joblib-0.14.0 nltk-3.5 num2words-0.5.10 numpy-1.19.1 pandas-0.24.2 pycountry-20.7.3 regex-2020.7.14 reporters-db-2.0.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.1 threadpoolctl-2.1.0 us-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "nltk",
                  "numpy",
                  "pandas",
                  "regex",
                  "requests",
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZyUO9bu15Ux"
      },
      "source": [
        "from six.moves import urllib\r\n",
        "import pandas as pd\r\n",
        "import lexnlp\r\n",
        "data = ''\r\n",
        "info_url= \"https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt\"\r\n",
        "text_doc = urllib.request.urlopen(info_url)\r\n",
        "\r\n",
        "for row in text_doc:\r\n",
        "  decoded = row.decode(\"utf-8\").replace('\\n', ' ')\r\n",
        "  if decoded :data = data + decoded"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3dyyit62CtT"
      },
      "source": [
        "Removing Punctuations\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqZgL3G2D8R"
      },
      "source": [
        "import string\r\n",
        "data = data.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJA6ZFs_2IQu"
      },
      "source": [
        "Acts\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-vMrb_B2KR7",
        "outputId": "70e5eb9f-c191-43b0-b13f-d4068bb6c35a"
      },
      "source": [
        "import lexnlp.extract.en.acts\r\n",
        "a= lexnlp.extract.en.acts.get_act_list(data)\r\n",
        "if a: \r\n",
        "  print(ACTS)\r\n",
        "else:\r\n",
        "  print('NO ACTS')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO ACTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMirX_6v2QTg",
        "outputId": "72456efc-e870-403d-a72c-b26c06a77b4c"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger') \r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP3T2rQU2TSA"
      },
      "source": [
        "Amounts\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtwHM8TQ2UFm",
        "outputId": "3d05d087-bca9-4df6-fb4c-aceca72190f0"
      },
      "source": [
        "import lexnlp.extract.en.amounts\r\n",
        "print(list(lexnlp.extract.en.amounts.get_amounts(data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Decimal('5.0'), Decimal('740.0'), Decimal('1843.0'), Decimal('2.0'), Decimal('1.0'), Decimal('4.0'), Decimal('2.0'), Decimal('5.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('80100.0'), Decimal('30.0'), Decimal('1839.0'), Decimal('741.0'), Decimal('1840.0'), Decimal('14000.0'), Decimal('120.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('3.0'), Decimal('4.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('2.0'), Decimal('1.0'), Decimal('361.0'), Decimal('1.0'), Decimal('307.0'), Decimal('6.0'), Decimal('604.0'), Decimal('1.0'), Decimal('2.0'), Decimal('418.0'), Decimal('422.0'), Decimal('7.0'), Decimal('34.0'), Decimal('41.0'), Decimal('167.0'), Decimal('742.0'), Decimal('3.0'), Decimal('112.0'), Decimal('207.0'), Decimal('3.0'), Decimal('338.0'), Decimal('424.0'), Decimal('5.0'), Decimal('26.0'), Decimal('13.0'), Decimal('235.0'), Decimal('8.0'), Decimal('693.0'), Decimal('4.0'), Decimal('1821.0'), Decimal('167.0'), Decimal('2.0'), Decimal('2.0'), Decimal('216.0'), Decimal('3.0'), Decimal('66.0'), Decimal('4.0'), Decimal('130.0'), Decimal('29.0'), Decimal('2.0'), Decimal('2412.0'), Decimal('332.0'), Decimal('2.0'), Decimal('422.0'), Decimal('9.0'), Decimal('112.0'), Decimal('743.0'), Decimal('9.0'), Decimal('39.0'), Decimal('14000.0'), Decimal('1840.0'), Decimal('744.0'), Decimal('5.0'), Decimal('182.0'), Decimal('3.0'), Decimal('368.0'), Decimal('1.0'), Decimal('397.0'), Decimal('6.0'), Decimal('604.0'), Decimal('1.0'), Decimal('1821.0'), Decimal('167.0'), Decimal('745.0'), Decimal('4.0'), Decimal('746.0'), Decimal('4.0'), Decimal('210.0'), Decimal('46.0'), Decimal('747.0'), Decimal('5.0'), Decimal('5.0'), Decimal('740.0'), Decimal('1843.0'), Decimal('284.0'), Decimal('2019.0'), Decimal('9.0'), Decimal('1.0'), Decimal('55.0'), Decimal('266.0'), Decimal('271.0'), Decimal('1876.0'), Decimal('2.0'), Decimal('47.0'), Decimal('362.0'), Decimal('376.0'), Decimal('1872.0'), Decimal('3.0'), Decimal('45.0'), Decimal('329.0'), Decimal('334.0'), Decimal('1871.0'), Decimal('4.0'), Decimal('31.0'), Decimal('526.0'), Decimal('527.0'), Decimal('1858.0'), Decimal('5.0'), Decimal('21.0'), Decimal('333.0'), Decimal('335.0'), Decimal('1852.0'), Decimal('6.0'), Decimal('8.0'), Decimal('145.0'), Decimal('147.0'), Decimal('1857.0'), Decimal('7.0'), Decimal('65.0'), Decimal('256.0'), Decimal('258.0'), Decimal('3.0'), Decimal('1880.0'), Decimal('8.0'), Decimal('4.0'), Decimal('913.0'), Decimal('914.0'), Decimal('1887.0'), Decimal('9.0'), Decimal('103.0'), Decimal('464.0'), Decimal('1936.0'), Decimal('3.0'), Decimal('1.0'), Decimal('9.0'), Decimal('39.0'), Decimal('1828.0'), Decimal('2.0'), Decimal('2.0'), Decimal('5.0'), Decimal('182.0'), Decimal('1837.0'), Decimal('2.0'), Decimal('3.0'), Decimal('9.0'), Decimal('108.0'), Decimal('1812.0'), Decimal('6.0'), Decimal('1.0'), Decimal('2.0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De1Hi0zb2dgW"
      },
      "source": [
        "Citations\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqOmtUpu2eMa",
        "outputId": "131f2954-23b6-4f7f-ee08-05983aa2277f"
      },
      "source": [
        "import lexnlp.extract.en.citations\r\n",
        "print(list(lexnlp.extract.en.citations.get_citations(data)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1843, 'WL', 'West Law Citation', 284, None, None, None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0KZGST12jHA"
      },
      "source": [
        "Companies\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBmnEPi2l4E",
        "outputId": "f0ed3428-757b-4a85-ffdc-2fcb17b61c1a"
      },
      "source": [
        "import lexnlp.extract.en.entities.nltk_re\r\n",
        "print(list(lexnlp.extract.en.entities.nltk_re.get_companies(data)))\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Lehman Durr Co, (17439, 17455)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVN0BIYE2ocq"
      },
      "source": [
        "Conditions\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcNSx80N2qvz",
        "outputId": "f1f11815-02e9-43b4-bbcb-becb5786a774"
      },
      "source": [
        "import lexnlp.extract.en.conditions\r\n",
        "print(list(lexnlp.extract.en.conditions.get_conditions(data)))\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('until', '5 Ala 740\\r Supreme Court of Alabama\\r ADAMS\\r v\\r TANNER AND HORTON\\r June Term 1843\\r Synopsis\\r WRIT of Error to the Circuit Court of Sumter\\r \\xa0\\r \\r \\r West Headnotes 2\\r \\r \\r 1\\r Chattel Mortgages\\r Crops\\r A growing crop has such an existence as to be the subjectmatter of a mortgage or other contract which passes an interest to vest in possession either immediately or at a future time\\r 4 Cases that cite this headnote\\r \\r 2\\r Creditors’ Remedies\\r Lien and Priority\\r Under St1821 prohibiting a levy on a crop', ''), ('until', 'it has been gathered no lien attaches in favor of a fi fa on a growing crop nor does such lien attach', ''), ('if', 'after the crop has been gathered\\r 5 Cases that cite this headnote\\r \\r 1 This was a trial of the right of property under the statute In November 1840 an execution issued from the circuit court of Sumter at the suit of the plaintiff in error requiring the sheriff of that county to make of the goods c of Allen Harrison and others the sum of thirtyseven hundred and seventyseven 80100 dollars besides costs This execution was levied on thirty bales of cotton as the property of Allen Harrison which was claimed and a bond given to try the right An issue was made up to try the question of the liability of the cotton to the plaintiff’s execution and submitted to a jury On the trial a bill of exceptions was sealed at the instance of the plaintiff The plaintiff proved that he recovered his judgment in October 1839 that an execution 741 was issued thereon on the 7th Nov thereafter and that alias and pluries fieri facias’ issued regularly up to the time levy was made that the cotton levied on was growed on the plantation of Harrison and cultivated by the hands in his service It was proved by the claimants by the production of a written contract that Harrison on the twentysecond of May 1840 in consideration that the claimants were involved as indorsers for Burton  Harrison of Sumter county and were then exposed to an execution amounting to upwards of fourteen thousand dollars bargained and sold to the claimants all his growing crop of cotton c consisting of one hundred and twenty acres c Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers', ''), ('where', 'the crop matured and was gathered he undertook to deliver the cotton in Gainesville The claimants came from Tennessee', ''), ('when', 'they resided about the first of September 1840 bringing with them three or four white laborers and took possession of the crop and slaves and with the latter and white laborers gathered the cotton prepared it for market and', ''), ('if', 'levied on it was in a warehouse in Gainesville The plaintiff then proved by Harrison that the claimants took possession of the crop while he was absent and disposed of it without his consent It was admitted that the contract was made in good faith\\r The court charged the jury that the plaintiff had no lien by virtue of his judgment and execution on the growing crop that Harrison had a right to convey it without being in any manner restrained by them that the writing adduced was a sale of the crop but', ''), ('when', 'it was not and the lien of the fieri facias would have attached upon it', ''), ('if', 'gathered yet', ''), ('not subject to', 'the claimants obtained possession on the first of September and controlled the gathering of the crop then no lien attached and it was', ''), ('until', 'the levy\\r Attorneys and Law Firms\\r R H SMITH for the plaintiff in error made the following points1 The crop of Harrison must in May 1840 have been in an immature state and it is insisted was not the subject of a sale 2 By the common law a growing crop could be levied on and sold 1 Salk Rep 361 1 Bos  P Rep 307 6 East’s Rep 604 note 1 2 Johns Rep 418 422 7 Mass Rep 34 and our statue Aik Dig § 41 p 167 which forbids the levy of an 742 execution on a growing crop is to receive a strict construction It merely inhibits the levy but the lien attaches and a levy and sale may be made after the crop matures and is gathered 3 The contract does not purport to convey the growing crop but is a mere executory agreement requiring some act to be done by Harrison in order to invest the claimants with the right of property Chit on Con 112 207 3 Johns Rep 338 424 5 Wend Rep 26 13 Johns Rep 235 8 Dowl Rep 693 and', ''), ('until', 'this act was done the crop no matter by who gathered because liable to be seized for Harrison’s debts A court of chancery would not compel a specific performance of the contract at the claimant’s instance 4 The charge of the court is also objectionable in deciding disputed facts\\r W M MURPHY with whom was W G JONES for the defendantcited the act of 1821 Aik Dig 167 which declares it to be lawful to levy an execution on a planted crop', ''), ('if', 'it is gathered and contended that no lien attached in favor of the plaintiff This being the case the defendant in execution was not restrained from making the contract which he did with the claimants\\r 2 The lien of an execution is destroyed by an injunction because it takes away the right to levy it In short whenever the right to levy an execution is but temporarily suspended or withdrawn the lien is during that time lost Whipple v Foot 2 Johns Rep 216 3 Wash C C Rep 66 4 How Rep 130\\r It is admitted that the contract between the defendant in execution and the claimants was in good faith', ''), ('when', 'so the severance and removal of the cotton gave the latter a good title against all creditors of the former\\r Opinion\\r \\r COLLIER C J\\r \\r There can be no doubt that a growing crop has such an existence as to be the subject matter of a sale mortgage or other contract which possess an interest to vest in possession either immediately or at some future time This proposition has frequently been assumed as unquestionable the point of inquiry generally being whether under a statute of frauds such as the 29 Chas 2 it is a mere chattel and transferrable by parol without writing Chitty on Con 2412 332 Whipple v Foot 2 Johns Rep 422 Stewart v Doughty 9 Johns Rep 112 743 Austin v Sawyer 9 Cow Rep 39 See also Ravesies v Lee  Alston at last term The contract set out in the bill of exceptions we are inclined to think evidences rather a mortgage than an absolute sale It recites that the claimants are involved as indorsers of a mercantile firm of which the defendant was a partner that an execution for upwards of fourteen thousand dollars against their estate is in the sheriff’s hands and that a conveyance is made of the crop of cotton corn and oats which the grantor agrees to give up at any time to the use of the claimants so as to prevent injury to them as indorsers The defendant in execution might at any time have divested the interest which the contract vested in the claimants by discharging their liability as his indorsers or a judgment creditor might have satisfied the lien and', ''), ('unless', 'the crop was gathered have levied on and sold it under a fieri facias\\r We will then consider the writing under which the claimants assert a right as a mortgage with a power to take possession any time during the year', ''), ('if', 'they should be relieved from their engagements as indorsers It is not pretended that their liability has been satisfied and it is admitted that the parties have acted with good faith so that it is a dry question of law whether the right of the plaintiff or the claimants shall prevail Assuming for the present that the execution of the plaintiffs did not operate a lien upon the planted crop previous to the contract of May 1840 we will inquire whether the defendant in execution had such an interest as could be levied on and sold\\r The claimants had previous to the levy of the execution taken possession of the crop prepared the cotton for market and removed it to a warehouse This possession it is insisted was a trespass because it was acquired in the absence of the defendant in execution and without his consent then given Conceding the truth of the facts stated in the bill of exceptions and we think it will not follow that the possession of the claimants is a nullity and that the case must be considered as', ''), ('if', 'they had never interfered with the crop The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity and', ''), ('if', 'they took possession of it in the absence of the grantor though without his consent', ''), ('if', 'he subsequently acquiesced in it the inference would be', ''), ('subject to', 'necessary that their acts were approved by him Taking this to be clear 744 law and it will be seen that the defendant in execution at the time of the levy had nothing more than a mere equitable right to redeem the cotton by paying the debts indorsed by the claimants He had no possession coupled with this equity but only a naked equity which it has been held cannot be reached by an ordinary execution Perkins and Elliott v Mayfield 5 Porter’s Rep 182\\r 3 This brings us back to the question whether the execution of the plaintiff was a lien on the growing crop so as to defeat the mortgage to the claimants It has been frequently mooted whether at common law corn c before it is gathered can be seized under a fieri facias Mr Dane in remarking upon this point says “The American editor of Bacon’s Abridgment says ‘Wheat growing in the ground is a chattel and', ''), ('until', 'be taken in execution and the sheriff may suffer it to grow till harvest and then cut and sell it or may perhaps sell it growing and the purchaser will then be entitled to enter for the purpose of cutting and carrying it away” He cites Whipple v Foot ut supra also Poole’s case Salk 368 1 Bos  P 397 6 East 604 n But Whipple v Foot seems to be the only case that supports his position that unripe wheat or corn may be taken in execution and the same editor states that nothing can be taken in execution which cannot be sold This position says the learned commentator is no doubt law But it is unnecessary to consider how this matter stands at common law The first section of the act of 1821 “To prevent sheriffs and other officers from levying executions in certain cases enacts that “It shall not be lawful for any sheriff or other officer to levy a writ of fieri facias or other execution on the planted crop of a debtor or person against whom an execution may issue', ''), ('until', 'the crop is gathered” Aik Dig 167 Now here is an express inhibition to levy an execution on a crop while it remains on or in the ground and', ''), ('if', 'it is severed from the soil to which it owes its growth In respect to property thus situated will the lien of an execution attach eo instanti upon its being placed in the hands of an officer', ''), ('until', 'so the act cited will only have the effect of keeping the right to levy it in abeyance', ''), ('if', 'the crop is gathered The lien of an execution does not only operate so as to prevent the debtor from disposing of the property on which it attaches but gives to the creditor the right to have it sold to satisfy his 745 judgment The lien and the right to levy are intimately connected and', ''), ('until', 'the latter be taken away or suspended the effect at common law is the destruction of the former This principle is fully established by Mansony and Hurtell v The President c of the Bank of the United States and its assignees and the citations contained in the opinion of the court in that case as also in my opinion in Wood v Gary et al both decided at the last term That it was competent for the legislature to have made it unlawful to levy an execution on particular property', ''), ('if', 'its condition was changed and still to give it a continuing lien cannot be doubted but there is nothing in the act in question to indicate that such is its intention', ''), ('until', 'the object was merely to suspend the sale', ''), ('as soon as', 'the crop was gathered it would have been very easy to have said so in explicit terms but declaring as the statute does in totidem verbis that the execution shall not be levied the legislature must be supposed to have meant what they have expressed The act was induced by the doubts which existed as to what was the common law and was intended to remove those doubts by declaring what should be the law in future It does not create a lien or authorize a levy in a case in which the law as it then existed was silent The idea that the lien attached upon the planted crop', ''), ('until', 'the execution was delivered to the sheriff though the right to levy it was postponed', ''), ('if', 'a severance took place is attempted to be deduced from the last words of the section cited viz “until the crop is gathered” These words cannot upon any just principles of construction be regarded so potent as to give to an execution a retrospective effect They do not refer to the lien', ''), ('until', 'they did they would postpone it', ''), ('until', 'the crop was gathered but it is the levy they relate to and postpone', ''), ('until', 'that event takes place\\r 4 The right to levy an execution on a planted crop then being expressly taken away by the statute the lien which is connected with and consequent upon that right never attaches', ''), ('if', 'severance This being the case the right of the defendant in execution to make the contract which he did is unquestionable and the title of the claimants coupled as it was with the possession was paramount to any lien which the execution could exert\\r The circuit judge may have mistaken the law in supposing that the contract was a sale but', ''), ('when', 'he did an error in that respect was very immaterial for whether a sale or mortgage as we have 746 seen under the facts of the case the defendant in execution has no interest that could be seised and sold under execution There is no assumption of any material fact in the charge but the possession of the claimant the time', ''), ('if', 'acquired the gathering of the crop c are all referred to the determination of the jury who are instructed', ''), ('until', 'they find them according to the evidence adduced that no lien ever attached in favor of the plaintiff The bona fides of the contract was conceded so that no charge was necessary on that point and it could not with propriety enter into the inquiry of the jury\\r It results from what has been said that the judgment of the circuit court is affirmed\\r \\r DISSENTING OPINION\\r \\r ORMOND J\\r 4 The statute which presents the question before the court is that “it shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution on the planted crop of a debtor or person against whom an execution may issue', ''), ('subject to', 'the crop is gathered” Clay’s Dig 210 § 46\\r I shall not enter upon the enquiry whether at common law an execution could be levied upon a growing crop though I apprehend it would not be difficult to maintain the affirmative of the proposition It is sufficient for my purpose that the statute supposes such to have been the law as it doubtless was the practice\\r This act must be considered in connection with the other acts upon the same subject The policy of the State as indicated by these statutes is undeniably that all the property of a debtor real and personal to which he has a legal title shall be', ''), ('until', 'sale by execution and it appears to me that it would be difficult to assign a reason for the exemption of this species of property from the claims of judgment creditors and for giving to the defendant in execution the right to dispose of it It appears to me with all deference that the argument that because the sheriff was prohibited from levying on a ““planted crop” that therefore the execution had lost its lien and the debtor had the right to sell it is a non sequitur The mischief which the statute designed to remedy was the sacrifice which would be necessarily made by the sale of an immature crop the statute enables the debtor to retain it', ''), ('if', 'it matures and by severing it from the soil to put it 747 in a condition to bring its valuethe lien in the mean time continuing in the plaintiff in execution\\r 5', ''), ('until', 'further confirmation of the correctness of this view were necessary it will be found I think in the language employed by the legislature The sheriff is forbidden to levy on a “planted crop”', ''), ('if', 'the crop is gathered Now', ''), ('until', 'the view taken by the majority of the court is correct the right secured to the plaintiff in execution of levying on the crop after it is gathered may be frustrated as it was in this case by a sale by the defendant in execution whilst the crop is in an immature state The construction which has been put upon the statute involves the singular anomaly that the legislature for the protection of the debtor has forbidden the plaintiff in execution to sell the property of his debtor because it is not in a condition to bring its value and yet permits the debtor voluntarily by a sale to submit to the same sacrifice for his own benefit It is in effect a gift to the defendant in execution of the growing crop provided he does not gather it himself but disposes of it in its then condition This I feel a thorough conviction was not the intention of the legislature but that it was to secure him from loss by prohibiting a levy and sale of the crop', ''), ('when', 'it was gathered', ''), ('subject to', 'the temporary suspension of the right to sell ceased\\r All Citations\\r 5 Ala 740 1843 WL 284\\r End of Document\\r © 2019 Thomson Reuters No claim to original US Government Works\\r Citing References 9\\r Treatment\\r Title\\r Date\\r Type\\r Depth\\r Headnotes\\r Cited by\\r 1  Booker v Jones’s Adm’x\\r 55 Ala 266 271  Ala\\r Trover for Conversion of Cotton with Counts in Case APPEAL from the Circuit Court of Hale Tried before the Hon M J SAFFOLD\\r Dec Term 1876\\r Case\\r —\\r Cited by\\r 2  Lehman Durr  Co v Marshall\\r 47 Ala 362 376  Ala\\r TROVER FOR CONVERSION OF COTTON APPEAL from the City Court of Montgomery Tried before Hon JOHN D CUNNINGHAM\\r Jan Term 1872\\r Case\\r —\\r Cited by\\r 3  Bibb v Janney\\r 45 Ala 329 334  Ala\\r GARNISHMENT WAGES WAIVER OF EXEMPTION APPEAL from City Court of Montgomery Tried before Hon JOHN D CUNNINGHAM\\r Jan Term 1871\\r Case\\r —\\r Cited by\\r 4  McKenzie v Lampley\\r 31 Ala 526 527  Ala\\r TRIAL OF RIGHT OF PROPERTY IN COTTON APPEAL from the Circuit Court of Barbour Tried before the Hon S D HALE\\r Jan Term 1858\\r Case\\r —\\r Cited by\\r 5  Evans v Lamar\\r 21 Ala 333 335  Ala\\r ERROR to the Circuit Court of Autauga Tried before the Hon A B MOORE\\r Jun Term 1852\\r Case\\r —\\r Cited by\\r  6  Dewey v Bowman\\r 8 Cal 145 147  Cal\\r The judgment of the Court below against Jacob S Cohen should be reversed for the following reasons Because the finding of the Court was so far as Cohen was concerned\\r Jul Term 1857\\r Case\\r —\\r Mentioned by\\r 7  Rees v Coats\\r 65 Ala 256 258  Ala\\r Trover for Conversion of Three Bales of Cotton APPEAL from the Circuit Court of Etowah Tried before the Hon WM L WHITLOCK\\r Nov Term 1880\\r Case\\r —\\r Mentioned by\\r 8  Edwards v Thompson\\r 4 SW 913 914  Tenn\\r Appeal from circuit court Weakley county\\r May 1887\\r Case\\r —\\r —\\r 9  Growing crops as', ''), ('subject to', 'levy and seizure under attachment or execution\\r 103 ALR 464\\r Generally at common law growing crops raised by annual planting while still attached to the soil are regarded as personal chattels', ''), ('where', 'levy and seizure under attachment\\r 1936\\r ALR\\r —\\r —\\r Table of Authorities 3\\r Treatment\\r Referenced Title\\r Type\\r Depth\\r Quoted\\r Page Number\\r Mentioned\\r 1  Austin v Sawyer\\r 9 Cow 39 NYSup 1828\\r Parol evidence is not admissible to contradict or substantially vary a written contract And', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYeI8_f-2yhu"
      },
      "source": [
        "Copy Rights\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBKW0S2j21Cy",
        "outputId": "460e28c2-acab-4081-eef2-dd618a70b787"
      },
      "source": [
        "import lexnlp.extract.en.copyright\r\n",
        "print(list(lexnlp.extract.en.copyright.get_copyright(data)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('©', '2019', 'Thomson Reuters No')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-uPCQtH25h4"
      },
      "source": [
        "Cusip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbXxElGZ27Lw"
      },
      "source": [
        "import lexnlp.extract.en.cusip\r\n",
        "c = list(lexnlp.extract.en.cusip.get_cusip(data))\r\n",
        "if c:\r\n",
        "  print(CUSIP)\r\n",
        "else:\r\n",
        "  print('NO CUSIP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTEaGF-t2_2k"
      },
      "source": [
        "Dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9AF73Ts2_OK",
        "outputId": "79884edb-829d-4041-b667-550b19d74ed3"
      },
      "source": [
        "import lexnlp.extract.en.dates\r\n",
        "print(list(lexnlp.extract.en.dates.get_dates(data)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SelectKBest from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  state = self.__dict__.copy()\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegressionCV from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  state = self.__dict__.copy()\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  state = self.__dict__.copy()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[datetime.date(2021, 6, 1), datetime.date(1840, 11, 1), datetime.date(1839, 10, 1), datetime.date(1840, 5, 1), datetime.date(1840, 9, 1), datetime.date(1840, 5, 1), datetime.date(1840, 5, 1), datetime.date(2021, 12, 1), datetime.date(2021, 12, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 3, 21), datetime.date(2021, 6, 1), datetime.date(2021, 7, 1), datetime.date(2021, 11, 1), datetime.date(1887, 5, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JG-yBEx3G-1"
      },
      "source": [
        "Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwkDIrHW3His",
        "outputId": "a98ebd07-e165-473f-d06c-b47d93072ff7"
      },
      "source": [
        "import lexnlp.extract.en.definitions\r\n",
        "def_= list(lexnlp.extract.en.definitions.get_definitions(data))\r\n",
        "if def_:\r\n",
        "  print('DEFINITIONS')\r\n",
        "else:\r\n",
        "  print('NO DEFINITIONS')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO DEFINITIONS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cDXLwYf3KOy"
      },
      "source": [
        "Distances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWczlM_r3L2v",
        "outputId": "81fd242f-28c6-459f-af71-f8ec2ed9dccb"
      },
      "source": [
        "import lexnlp.extract.en.distances\r\n",
        "dist_ = list(lexnlp.extract.en.distances.get_distances(data))\r\n",
        "if dist_:\r\n",
        "  print('DISTANCES')\r\n",
        "else:\r\n",
        "  print('NO DISTANCES')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO DISTANCES\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhz327bZ3OPz"
      },
      "source": [
        "Durations\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsCyIXoQ3P3t",
        "outputId": "92f6f578-3f0b-4769-d123-d2d3433e6871"
      },
      "source": [
        "import lexnlp.extract.en.durations\r\n",
        "print(list(lexnlp.extract.en.durations.get_durations(data)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('year', Decimal('6.0'), Decimal('2190.0'))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqD21WbD3SPu"
      },
      "source": [
        "Money"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9sTOnK03UD_",
        "outputId": "a7450c1a-2851-47ca-a48b-f75f96435af3"
      },
      "source": [
        "import lexnlp.extract.en.money\r\n",
        "print(list(lexnlp.extract.en.money.get_money(data)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(Decimal('80100.0'), 'USD'), (Decimal('14000.0'), 'USD'), (Decimal('14000.0'), 'USD')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8520Qt7m3WNX"
      },
      "source": [
        "Percents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YIKnoxO3YJt",
        "outputId": "36b72722-7bec-4884-fe7c-fcf22250a132"
      },
      "source": [
        "import lexnlp.extract.en.percents\r\n",
        "per_= list(lexnlp.extract.en.percents.get_percents(data))\r\n",
        "if per_:\r\n",
        "  print('PERCENTS')\r\n",
        "else:\r\n",
        "  print('NO PERCENTS')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO PERCENTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_RqHzyE3bjA"
      },
      "source": [
        "Pii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCgXn8ao3eQT",
        "outputId": "b7cab2fe-1151-4e32-a3d0-df341fca6570"
      },
      "source": [
        "import lexnlp.extract.en.pii\r\n",
        "p_ii = list(lexnlp.extract.en.pii.get_pii(data))\r\n",
        "if p_ii:\r\n",
        "  print('PII')\r\n",
        "else:\r\n",
        "  print('NO PII')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO PII\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA8OMLHu3gss"
      },
      "source": [
        "Ratios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAzvw0IW3iRe"
      },
      "source": [
        "import lexnlp.extract.en.ratios\r\n",
        "ratios_ = list(lexnlp.extract.en.ratios.get_ratios(data))\r\n",
        "if ratios_:\r\n",
        "  print('RATIOS')\r\n",
        "else:\r\n",
        "  print('NO RATIOS')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O30r0Mf3uZf"
      },
      "source": [
        "Regulations\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npZ-4jPp3wmh",
        "outputId": "c2cf9cc6-2bb5-42a8-d2e1-7245865dda26"
      },
      "source": [
        "import lexnlp.extract.en.regulations\r\n",
        "reg_ = list(lexnlp.extract.en.regulations.get_regulations(data))\r\n",
        "if reg_:\r\n",
        "  print('REGULATIONS')\r\n",
        "else:\r\n",
        "  print('NO REGULATIONS')\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO REGULATIONS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW9McUEp30kU"
      },
      "source": [
        "Trademarks\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_1uTsX032oL",
        "outputId": "e24df057-7d68-4a5d-8e89-bdbbe994a6e1"
      },
      "source": [
        "import lexnlp.extract.en.trademarks\r\n",
        "trade_marks_ = list(lexnlp.extract.en.trademarks.get_trademarks(data))\r\n",
        "if trade_marks_:\r\n",
        "  print('TRADEMARKS')\r\n",
        "else:\r\n",
        "  print('NO TRADEMARKS')\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO TRADEMARKS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDaQ8C_J35d_"
      },
      "source": [
        "Urls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzT8NuF-37tz",
        "outputId": "f4d4a6b2-1658-4f3e-8cb8-a87fc20e9f1c"
      },
      "source": [
        "import lexnlp.extract.en.urls\r\n",
        "url_s_= list(lexnlp.extract.en.urls.get_urls(data))\r\n",
        "if url_s_:\r\n",
        "  print('URLS')\r\n",
        "else:\r\n",
        "  print('NO URLS')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NO URLS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sOAuj344AH7"
      },
      "source": [
        "Addresses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Crf_6pC4B9q",
        "outputId": "ca7e8913-35d4-4bae-c4fe-7a51ca2a4d0c"
      },
      "source": [
        "!pip install pyap\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyap\n",
            "  Downloading https://files.pythonhosted.org/packages/53/b2/f0f962a5385d54cd91c153df93932b4996b793f1a2145807823d7f71328d/pyap-0.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pyap\n",
            "Successfully installed pyap-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRsPVQ8V4G7c",
        "outputId": "61c2a454-e141-412f-cf80-41336443ebff"
      },
      "source": [
        "import pyap\r\n",
        "ad_ = pyap.parse(data, country='US')\r\n",
        "for address in ad_:\r\n",
        "  print(address)\r\n",
        "  print(address.as_dict())\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 Ala 740 Supreme Court of Alabama ADAMS\n",
            "{'full_address': '5 Ala 740 Supreme Court of Alabama ADAMS', 'full_street': '5 Ala 740 Supreme Court', 'street_number': '5', 'street_name': 'Ala 740 Supreme', 'street_type': 'Court', 'route_id': None, 'post_direction': None, 'floor': None, 'building_id': None, 'occupancy': None, 'city': 'of Alabama ADA', 'region1': 'MS', 'postal_code': None, 'country_id': 'US', 'match_start': 1, 'match_end': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i9YV5W-4LWA"
      },
      "source": [
        "Person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOCNFkgm4SuH",
        "outputId": "d2d3e9df-499e-4223-dff3-7235a6ffac11"
      },
      "source": [
        "import spacy\r\n",
        "nlp_  = spacy.load('en_core_web_sm')\r\n",
        "text_doc = nlp_(data.strip())\r\n",
        "person_= set()\r\n",
        "for x in text_doc.ents:\r\n",
        "  entry = str(x.lemma_).lower()\r\n",
        "  text_sample = data.replace(str(x).lower(), \"\")\r\n",
        "  if x.label_ == \"PERSON\":\r\n",
        "    person_.add(entry.title())\r\n",
        "person_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ala',\n",
              " 'Ala \\r  Error',\n",
              " 'Allen Harrison',\n",
              " 'Alston',\n",
              " 'Austin',\n",
              " 'Booker',\n",
              " 'Burton   Harrison',\n",
              " 'Case',\n",
              " 'Cohen',\n",
              " 'Dewey',\n",
              " 'Dowl Rep',\n",
              " 'Edwards',\n",
              " 'Elliott',\n",
              " 'Evans',\n",
              " 'Harrison',\n",
              " 'Jacob S Cohen',\n",
              " 'Janney',\n",
              " 'Lamar',\n",
              " 'Lampley \\r  31',\n",
              " 'Lien',\n",
              " 'Lien Attach',\n",
              " 'Mansony',\n",
              " 'Marshall',\n",
              " 'Perkins',\n",
              " 'Sawyer',\n",
              " 'Stewart',\n",
              " 'Sumter',\n",
              " 'W G Jones',\n",
              " 'Whipple',\n",
              " 'Wood'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}